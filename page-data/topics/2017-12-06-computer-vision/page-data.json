{"componentChunkName":"component---src-templates-blog-post-js","path":"/topics/2017-12-06-computer-vision/","result":{"data":{"site":{"siteMetadata":{"title":"Won"}},"markdownRemark":{"id":"a356d8ba-737e-5f89-857a-47f6017b7be2","excerpt":"What is Computer Vision? Acquiring, processing, analyzing, and understanding visual data in order to produce numerical or symbolic information.wikipedia Human…","html":"<h1>What is Computer Vision?</h1>\n<p>Acquiring, processing, analyzing, and understanding visual data in order to produce numerical or symbolic information.[wikipedia]</p>\n<h1>Human Eyes</h1>\n<ul>\n<li><a href=\"https://ko.wikipedia.org/wiki/%EA%B0%84%EC%83%81%EC%84%B8%ED%8F%AC\">간상세포 (약한 빛, 운동)</a></li>\n<li><a href=\"https://ko.wikipedia.org/wiki/%EC%9B%90%EC%B6%94%EC%84%B8%ED%8F%AC\">원추세포 (시세포로 색을 감지)</a></li>\n</ul>\n<h1>Topics in Computer Vision</h1>\n<ul>\n<li>\n<p>Low-level vision (early vision)</p>\n<ul>\n<li>Image formation</li>\n<li>Image filtering</li>\n<li>Optical flow</li>\n<li>Image segmentation</li>\n<li>Stereopsis</li>\n</ul>\n</li>\n<li>\n<p>Mid-level</p>\n<ul>\n<li>Object tracking</li>\n<li>Human motion analysis</li>\n</ul>\n</li>\n<li>\n<p>High-level vision</p>\n<ul>\n<li>Object recognition</li>\n<li>Event detection</li>\n<li>Scene &#x26; video understanding</li>\n</ul>\n</li>\n</ul>\n<h1>Python Image Library</h1>\n<ul>\n<li>\n<p><a href=\"https://pillow.readthedocs.io/en/4.3.x/\">Pillow</a></p>\n<ul>\n<li>Pillow(PIL fork) provides general image handling and lots of useful basic image operations like resizing, cropping, rotating, color conversion and much more.</li>\n</ul>\n</li>\n</ul>\n<h1>Image</h1>\n<ul>\n<li>Images are stored in 2D or 3D arrays.</li>\n<li>Images can be dealt with as a function</li>\n</ul>\n<h1>What is Image Histogram?</h1>\n<ul>\n<li>A histogram is a distribution of pixel values - each bin has a count of how many pixels have the value.</li>\n</ul>\n<h1>What is Histogram Equalization?</h1>\n<ul>\n<li>Flattens the histogram so that all intensities are as equally common as possible.</li>\n</ul>\n<h1>What is Image Filtering?</h1>\n<ul>\n<li>Filtering is a technique for modifying or enhancing an image. For example, you can filter an image to emphasize certain features or remove other features. Image processing operations implemented with filtering include smoothing, sharpening, and edge enhancement.</li>\n<li>\n<p>Application of Filtering</p>\n<ul>\n<li>Enhance an image, e.g., denoise, resize.</li>\n<li>Extract information, e.g., texture, edges.</li>\n<li>Detect patterns, e.g., template matching.</li>\n</ul>\n</li>\n</ul>\n<h1>Linear Filtering</h1>\n<ul>\n<li>\n<p>Correlation Filtering</p>\n<ul>\n<li>Involves weighted combinations of pixels in small neighborhoods.</li>\n<li>The output pixels value is determined as a weighted sum of input pixel values</li>\n<li>Filter coefficients</li>\n</ul>\n</li>\n<li>Convolution Filtering</li>\n<li>Symmetric kernel has same results of correlation and convolution filtering.</li>\n</ul>\n<h1>Separable Linear Filtering</h1>\n<ul>\n<li>The process of performing a convolution requires K2 operations per pixel, where K is the size (width or height) of the convolution kernel.</li>\n<li>In many cases, this operation can be speed up by first performing a 1D horizontal convolution followed by a 1D vertical convolution, requiring 2K operations.</li>\n<li>\n<p>If this is possible, then the convolution kernel is called separable.</p>\n<ul>\n<li><strong>K = vh<sup>T</sup></strong></li>\n</ul>\n</li>\n</ul>\n<hr>\n<h1>Study Catalog</h1>\n<p>Image Histogram</p>\n<p>Histogram Equalization</p>\n<p>Image Filtering</p>\n<p>Linear Filtering</p>\n<ul>\n<li>Weight Kernel</li>\n<li>correlation</li>\n<li>convolution</li>\n</ul>\n<p>Padding</p>\n<ul>\n<li>zero</li>\n<li>warp</li>\n<li>clamp</li>\n<li>mirror</li>\n</ul>\n<p>Image Derivatives</p>\n<ul>\n<li>Prewitt</li>\n<li>Sobel (x-derivative, y-derivative, magnitude)</li>\n<li>Gaussian (sigma 2, 5, 10)</li>\n</ul>\n<p>Separable Linear Filters</p>\n<ul>\n<li>box</li>\n<li>bilinear</li>\n<li>Gaussian</li>\n<li>Sobel</li>\n<li>corner\nGaussian Pyramid</li>\n</ul>\n<p>Morphology</p>\n<ul>\n<li>Thresholding function</li>\n<li>Dilation</li>\n<li>Erosion</li>\n<li>Majority</li>\n<li>Opening</li>\n<li>Closing</li>\n<li>Counting Object</li>\n</ul>\n<p>Distance Transform\nConnected components</p>\n<p>Edge and lines</p>\n<p>Detecting edges\n2D edge detection filters</p>\n<ul>\n<li>Gaussian</li>\n<li>Derivative</li>\n<li>Laplacian\nDirectional Derivatives</li>\n</ul>\n<p>Canny Edge Detector</p>\n<ul>\n<li>Hysteresis Thresholding</li>\n<li>Scale Selection</li>\n<li>Scale</li>\n</ul>\n<p>Line Detection</p>\n<ul>\n<li>Successive Approximation</li>\n<li>Hough Transform</li>\n</ul>\n<hr>\n<p>Local Image Descriptors</p>\n<p>Invariant Local features\nCorner Detection</p>\n<ul>\n<li>Approximation</li>\n<li>Harris Corner Detector</li>\n<li>FAST</li>\n</ul>\n<p>Feature Detection</p>\n<ul>\n<li>Rotation invariance</li>\n<li>Scale Invariance</li>\n</ul>\n<p>Feature Descriptors</p>\n<ul>\n<li>MOPS</li>\n<li>SIFT</li>\n<li>SURF</li>\n<li>\n<p>Binary Descriptors</p>\n<ul>\n<li>BRIEF</li>\n<li>BRISK</li>\n<li>ORB\nKAZE Feature</li>\n</ul>\n</li>\n<li>Edge-preserving blur\nHOG Feature\nFeature Matching</li>\n<li>NNDR</li>\n<li>Greedy approach</li>\n<li>Hungarian method</li>\n</ul>\n<p>Image Transformations</p>\n<ul>\n<li>translation</li>\n<li>Euclidean</li>\n<li>similarity</li>\n<li>affine</li>\n<li>projective (homography)</li>\n</ul>\n<p>2D Parametric Transformations</p>\n<ul>\n<li>translation</li>\n<li>rigid(Euclidean)</li>\n<li>similarity</li>\n<li>affine</li>\n<li>projective</li>\n</ul>\n<p>Degree of Freedom</p>\n<p>The number of independent pieces of information that go into the estimate of a parameter is called the degrees of freedom (DOF). In this guide, DOF are given for 3D images.</p>\n<p>each of a number of independently variable factors affecting the range of states in which a system may exist, in particular.</p>\n<p>Image Warping</p>\n<ul>\n<li>Forward Warping</li>\n<li>Inverse warping</li>\n<li>linear interpolation</li>\n<li>Homogeneous Coordinate</li>\n</ul>\n<p>Homography Estimation</p>\n<ul>\n<li>(DLT) Direct linear transform</li>\n</ul>\n<p>Robust Parameter Estimation</p>\n<ul>\n<li>RANSAC</li>\n<li>Estimation Refinement(개선)</li>\n<li>LLS</li>\n<li>NLS</li>\n<li>LM Algorithm</li>\n<li>Robust Least-Squares</li>\n</ul>\n<p>Parameter Estimation Summary\nTo estimate the parameters of a model for the noisy data:</p>\n<ul>\n<li>DLT works only for noise-free data.</li>\n<li>Use RANSAC or similar to filter the outliers.</li>\n<li>Use optimization for the inliers with the RANSAC result as the initial parameter.</li>\n<li>Even after RANSAC filtering, using a robust norm in optimization is desired.\nPanorama Stitching</li>\n</ul>\n<hr>\n<p>Image Formation</p>\n<ul>\n<li>Pinhole Camera Model</li>\n<li>Projection</li>\n<li>Projection matrix</li>\n<li>Parallel lines meet in the image</li>\n<li>3d 2d projection</li>\n<li>Camera Intrinsics</li>\n<li>Perspective Projection</li>\n<li>Variable Aperture</li>\n<li>Lense</li>\n<li>Depth of field</li>\n<li>Lens Distortion</li>\n<li>Tilt-shift</li>\n<li>Photometric image formation</li>\n<li>Vignetting: Spatial Non-Uniformity</li>\n<li>Camera Sensor</li>\n<li>Color Separation</li>\n</ul>\n<hr>\n<p>Structure from motion</p>\n<p>Triangulation\nP3P Pose Estimation\nEpipolar Geometry\nTwo-frame structure from motion\nBundle Adjustment</p>\n<ul>\n<li>Least squares</li>\n</ul>\n<p>2D Homography\nPlanar Homography\nPure Rotation</p>\n<p>Summary</p>\n<ul>\n<li>\n<p>Image forma0on by pinhole camera model.</p>\n<ul>\n<li>Camera intrinsics convertng between pixel coordinates and 3D rays.</li>\n<li>Perspectve projec0on.</li>\n</ul>\n</li>\n<li>\n<p>Homogeneous coordinates and 2D and 3D transformations.</p>\n<ul>\n<li>2D homography — pure rota0on and planar homography.</li>\n</ul>\n</li>\n<li>Triangula0on and 3D pose es0ma0on.</li>\n<li>\n<p>Epipolar geometry.</p>\n<ul>\n<li>Two-view structure from mo0on.</li>\n</ul>\n</li>\n<li>RANSAC.</li>\n<li>Bundle adjustment.</li>\n</ul>\n<hr>\n<p>Dense Stereo and Depth Estimation</p>\n<p>Binocular Stereopsis\nconverging cameras\nmotion parallel with image plane\nforward motion\nStereo Calibration\nStereo Rectification\nStereo Disparity\nSparse Correspondences\nDense Correspondence\nLighting Conditions (Photometric)\nAmbiguity\nMultiple Interpretations\nWindow\nProblem of Occlusion\nStereo Constraints\nWindow correlation\nglobal optimization</p>\n<p>Stereo matching\nDynamic programming\nSegmentation-based techniques\nGlobal Optimization\nMulti-view stereo</p>\n<p>Depth Estimation</p>\n<p>Lense Array (Integral Imaging)\nStructured light\nlaser scanning\ntime of flight</p>\n<p>Summary</p>\n<ul>\n<li>Triangulation and epipolar geometry</li>\n<li>Stereo camera calibration and rectification</li>\n<li>Sparse / dense correspondence</li>\n<li>Local methods / global optimization</li>\n<li>Multi-view stereo </li>\n</ul>\n<hr>\n<p>Visual tracking</p>\n<p>Mean-shift Algorithm\nMain-shift vector\nScale Selection\nCamshift Tracking\nProbalbilistic Formation of visual tracking\nKalman Filtering\nBayesian Filtering\nParticle Filtering\nObject Model for tracking\nExample: Condensation\nAppearance Model\nMotion Model\nExample: Incremental Visual Tracking\nObject state estimation\nTracking as an optimization\nOptimization methods\nIterative Closest Point\nCMA-ES\nNon-rigid Surface Tracking using CMA-ES and NURBS\nPhysical simulation\nTracking Deformable Objects with Point Clouds</p>\n<p>MIL Tracker\nL1 Tracker\nHough Track\nTracking-Learning-Detection\nBenchmark Evaluation</p>\n<p>Summary</p>\n<ul>\n<li>\n<p>Visual tracking:</p>\n<ul>\n<li>Probabilistic inference : estimation of posterior probability density.</li>\n<li>Optimization : state which gives the minimum cost.</li>\n</ul>\n</li>\n<li>\n<p>Object models</p>\n<ul>\n<li>Appearance/shape model</li>\n<li>Motion model</li>\n</ul>\n</li>\n<li>Generative / discriminative approaches.</li>\n<li>Thorough evaluation on tracking accuracy or robustness. </li>\n</ul>\n<hr>\n<p>Clustering and Segmentation</p>\n<p>Data clustering problem\nClustering Algorithms</p>\n<ul>\n<li>\n<p>Hierarchical methods</p>\n<ul>\n<li>Agglomerative clustering</li>\n<li>divisive clustering</li>\n</ul>\n</li>\n<li>\n<p>Iterative methods</p>\n<ul>\n<li>k-means clustering</li>\n<li>EM algorithm</li>\n<li>Mean-shift algorithm</li>\n</ul>\n</li>\n<li>\n<p>Spectral clustering</p>\n<ul>\n<li>Normalized cut</li>\n</ul>\n</li>\n</ul>\n<p>Data Affinity</p>\n<p>Clustering in computer vision</p>\n<ul>\n<li>image segmentation</li>\n<li>foreground/background segmentation</li>\n<li>feature clustering</li>\n<li>image/video categorization</li>\n</ul>\n<p>k-Means Clustering Procedure</p>\n<ol>\n<li>Randomly select k-means.2. Find the association of all samples to the k-means.3. Move the locations of k-means to the mean of the associated samples.</li>\n<li>Goto the step 2 and iterate until convergence.</li>\n</ol>\n<p>Sensitivity to outliers\nSegmentation by graph partitioning\nmeasuring affinity\nminimum cut\nminimum graph cut\nSolving normalized cut</p>\n<hr>\n<p>Detection and Recognition</p>\n<p>PCA and FLD</p>\n<p>Evaluating classifier\nclassifier and Error rates</p>\n<p>Support Vector Machine\nBinary classification\nLinear classifiers</p>\n<p>Perceptron Algorithm</p>\n<p>Large margin classifier\nDual Formulation\nEmpirical Risk and True Risk\nVC Dimension\nCapacity of Functions\nCapacity of Hyperplanes\nLinear Support Vector Machine\nSoft-margin Formulation\nSoft-margin Optimization\nGradient-descent Algorithm for SVM training\nNon-linear Support Vector Machine\nThe Kernel Tricks</p>\n<p>AdaBoost and Face Recognition\nBoosting Approach\nPAC Learning\nBoostring Algorithm\nCharacteristics of AdaBoost\nFace Detection by AdaBoost\nIntegral Image\nLearning Results\nAttentional Cascade\nCascaded Classifier</p>\n<hr>\n<p>Deep Learning</p>\n<p>AI - NEURAL NETWORK\n• Neural Network• Backpropagation• Activation Function\n• Dropout</p>\n<hr>\n<h1>References</h1>\n<ul>\n<li><a href=\"http://sebastianraschka.com/Articles/2014_python_lda.html\">http://sebastianraschka.com/Articles/2014_python_lda.html</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Linear_discriminant_analysis\">https://en.wikipedia.org/wiki/Linear_discriminant_analysis</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Principal_component_analysis\">https://en.wikipedia.org/wiki/Principal_component_analysis</a></li>\n<li><a href=\"https://wikidocs.net/5957\">https://wikidocs.net/5957</a></li>\n<li><a href=\"http://sanghyukchun.github.io/72/\">http://sanghyukchun.github.io/72/</a></li>\n<li><a href=\"https://github.com/rushinshah7942/Classification-and-Regression\">https://github.com/rushinshah7942/Classification-and-Regression</a></li>\n<li><a href=\"https://github.com/jayavardhanravi/FLD/tree/master/mypart1\">https://github.com/jayavardhanravi/FLD/tree/master/mypart1</a></li>\n<li><a href=\"http://benalexkeen.com/k-means-clustering-in-python/\">http://benalexkeen.com/k-means-clustering-in-python/</a></li>\n<li><a href=\"http://adnoctum.tistory.com/442\">http://adnoctum.tistory.com/442</a></li>\n<li><a href=\"http://docs.scipy.org/doc/scipy/reference/tutorial/ndimage.html\">http://docs.scipy.org/doc/scipy/reference/tutorial/ndimage.html</a> <a href=\"http://scipy-lectures.github.io/advanced/image_processing/\">http://scipy-lectures.github.io/advanced/image_processing/</a> <a href=\"http://nbviewer.ipython.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-4-Matplotlib.ipynb\">http://nbviewer.ipython.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-4-Matplotlib.ipynb</a></li>\n<li><a href=\"http://scikit-learn.org/stable/index.html#\">http://scikit-learn.org/stable/index.html#</a></li>\n</ul>\n<hr>\n<h1><a href=\"https://classroom.udacity.com/courses/ud955\">Computational Photography</a></h1>\n<hr>\n<h1><a href=\"https://www.udacity.com/course/introduction-to-computer-vision--ud810\">Introduction to Computer Vision</a> (2017-11)</h1>\n<hr>\n<h1>Computer Vision Topics</h1>\n<ol>\n<li>Image formation and optics</li>\n<li>Image processing, filtering, Fourier analysis</li>\n<li>Pyramids and wavelets</li>\n<li>Feature extraction</li>\n<li>Image matching</li>\n<li>Bag of words</li>\n<li>Optical flow</li>\n<li>Structure from motion</li>\n<li>Multi view stereo</li>\n<li>Segmentation</li>\n<li>Clustering</li>\n<li>Viola-Jones</li>\n<li>Bayesian techniques</li>\n<li>Machine learning</li>\n<li>RANSAC and robust techniques</li>\n<li>Numerical methods</li>\n<li>Optimization</li>\n<li>Range finding, active illumination</li>\n<li>Algorithms</li>\n<li>Graph cuts</li>\n<li>Dynamic programming</li>\n<li>Complexity analysis</li>\n<li>MATLAB and C++. and assembly (optional: GPU programming)</li>\n<li>Communication and presentation skills</li>\n</ol>\n<h3>Image and features</h3>\n<p>• NCC\n• Interest point operators\n• Scale invariant and affine invariant detectors &#x26; descriptors\n• Scale space\n• Image processing, filtering, Fourier analysis\n• Pyramids and wavelets\n• Edge detection\n• Restoration e.g. deblurring, super-resolution\n– Linear, e.g. Wiener filter\n– MRF\n– Non-local means/BM3D/bilateral filter</p>\n<h3>Segmentation, grouping and tracking</h3>\n<p>• Segmentation\n– Normalized cuts\n• Grouping\n– Hough transforms\n• Clustering\n– K-means\n– Mean-shift\n– Pedro-clustering\n• Tracking\n– Kalmanfilter\n– Particle filter</p>\n<h3>Multi-view: stereo, SFM, flow</h3>\n<p>• RANSAC and other robust techniques\n• Geometry:\n– epipolar geometry (projective and affine)\n– planar homographies\n– Affine camera\n• Geometry estimators\n– 8 point algorithm for F\n– 4 point algorithm for H\n• Factorization\n• Bundle-adjustment\n• Flow\n– Horn &#x26; Schunck L2\n– Lucas-Kanade\n– L1 regularized</p>\n<h3>Recognition</h3>\n<ul>\n<li>Bag of visual words</li>\n<li>HOG, SIFT, GIST</li>\n<li>Spatial pyramid</li>\n<li>Spatial configurations/Pictorial structures</li>\n<li>Sliding window/jumping window</li>\n<li>\n<p>Cascades\n​</p>\n<h3>Others</h3>\n<h4>Machine Learning</h4>\n</li>\n<li>Adaboost</li>\n<li>kNN</li>\n<li>SVM</li>\n<li>Random forest</li>\n<li>PCA, ICA, CCA</li>\n<li>EM</li>\n<li>MIL/Latent-SVM</li>\n<li>Regularization</li>\n<li>HMM</li>\n<li>Graphical &#x26; Bayesian models</li>\n</ul>\n<h4>Optimization</h4>\n<ul>\n<li>Classical linear and non-linear</li>\n<li>Graph operations</li>\n<li>Dynamic programming/message passing for MAP, max-marginals</li>\n<li>Graph cuts for binary variable MAP</li>\n<li>Texture synthesis</li>\n</ul>","frontmatter":{"title":"Computer Vision","date":"December 05, 2017","description":"Acquiring, processing, analyzing, and understanding visual data in order to produce numerical or symbolic information.[wikipedia]"}}},"pageContext":{"slug":"/topics/2017-12-06-computer-vision/","previous":{"fields":{"slug":"/2017-11-30-terms/"},"frontmatter":{"title":"Terms"}},"next":{"fields":{"slug":"/python/2018-01-17-python-01/"},"frontmatter":{"title":"Python study"}}}},"staticQueryHashes":["240262808","2841359383"]}